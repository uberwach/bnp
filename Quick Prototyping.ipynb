{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import extraction\n",
    "import util\n",
    "from time import time\n",
    "\n",
    "X, y, X_holdout, ids = extraction.prepare_data(\"./data/\", drop_categorical=True)\n",
    "\n",
    "def create_submission(clf, submission_name):\n",
    "    file_name = submission_name + \"_{}.csv\".format(time())\n",
    "    util.note_submission_info(\"Model: {}\".format(clf), file_name)\n",
    "    util.build_submission(clf, X_holdout, ids, file_name)\n",
    "    print \"Written {}\".format(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112 features, 114321 data points\n"
     ]
    }
   ],
   "source": [
    "print \"{} features, {} data points\".format(X.shape[1], X.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Quickfix: X_holdout is still broken (NaNs)!\n",
    "import scipy.stats as stats\n",
    "import numpy as np\n",
    "\n",
    "col_mean = stats.nanmean(X_holdout,axis=0)\n",
    "inds = np.where(np.isnan(X_holdout))\n",
    "X_holdout[inds]=np.take(col_mean,inds[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics, cross_validation\n",
    "\n",
    "def check_cv_score(clf, X, y):\n",
    "    scores = cross_validation.cross_val_score(clf, X, y, scoring=\"log_loss\", cv=5, n_jobs=-1, verbose=1)\n",
    "    \n",
    "    mu = scores.mean()\n",
    "    std = scores.std()\n",
    "    \n",
    "    return mu, std\n",
    "\n",
    "def report_metrics(clf, X_test, y_test):\n",
    "    y_pred = clf.predict_proba(X_test)[:,0]\n",
    "\n",
    "    print \"Log loss: {}\".format(metrics.log_loss(y_test, y_pred))\n",
    "    print \"Accuracy: {}\".format(clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = cross_validation.train_test_split(X, y, test_size=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GBT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           1.0900           0.0097            5.45m\n",
      "         2           1.0803           0.0085            4.60m\n",
      "         3           1.0731           0.0076            4.29m\n",
      "         4           1.0645           0.0069            4.11m\n",
      "         5           1.0585           0.0064            3.98m\n",
      "         6           1.0541           0.0059            3.89m\n",
      "         7           1.0497           0.0055            3.80m\n",
      "         8           1.0387           0.0047            3.73m\n",
      "         9           1.0393           0.0043            3.66m\n",
      "        10           1.0351           0.0039            3.61m\n",
      "        20           1.0060           0.0016            3.13m\n",
      "        30           0.9943           0.0007            2.72m\n",
      "        40           0.9849           0.0005            2.31m\n",
      "        50           0.9745           0.0001            1.91m\n",
      "        60           0.9727           0.0004            1.51m\n",
      "        70           0.9694           0.0000            1.16m\n",
      "        80           0.9643           0.0000           48.20s\n",
      "        90           0.9619           0.0002           24.66s\n",
      "       100           0.9593          -0.0000            0.00s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(init=None, learning_rate=0.05, loss='deviance',\n",
       "              max_depth=5, max_features=None, max_leaf_nodes=None,\n",
       "              min_samples_leaf=1, min_samples_split=2,\n",
       "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "              random_state=42, subsample=0.8, verbose=1, warm_start=False)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time\n",
    "gbt_clf = GradientBoostingClassifier(n_estimators=100, \n",
    "                                     max_depth=5, \n",
    "                                     subsample=0.8,\n",
    "                                     learning_rate=0.05,\n",
    "                                     verbose=1, \n",
    "                                     random_state=42)\n",
    "gbt_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log loss: 1.43415375728\n",
      "Accuracy: 0.77827341905\n",
      "Written gbt_1454880935.65.csv\n"
     ]
    }
   ],
   "source": [
    "report_metrics(gbt_clf, X_test, y_test)\n",
    "create_submission(gbt_clf, \"gbt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from visualization import learning_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig = learning_curve.plot_learning_curve(title=\"Learning curve of decision stump GBT\", \n",
    "                                   estimator=gbt_clf, X=X[:5000], y=y[:5000], n_jobs=4, cv=5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_clf = RandomForestClassifier(random_state=42, verbose=1)\n",
    "rf_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "report_metrics(rf_clf, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
